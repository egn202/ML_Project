{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578, 167)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 50\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "housing = pd.read_csv('/Users/Eugene/OneDrive/ML/ML_Project/Group/housing.csv', index_col=0)\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "housetarg = pd.Series(housing.SalePrice_Log, name='target')\n",
    "housefeature = housing.drop('SalePrice_Log',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(housefeature, housetarg)\n",
    "Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alphas = np.linspace(0.001,10,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Gridsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "#randomized is faster\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Lasso(normalize=True),\n",
       "             param_grid={'alpha': array([1.000e-03, 1.020e-01, 2.030e-01, 3.040e-01, 4.050e-01, 5.060e-01,\n",
       "       6.070e-01, 7.080e-01, 8.090e-01, 9.100e-01, 1.011e+00, 1.112e+00,\n",
       "       1.213e+00, 1.314e+00, 1.415e+00, 1.516e+00, 1.617e+00, 1.718e+00,\n",
       "       1.819e+00, 1.920e+00, 2.021e+00, 2.122e+00, 2.223e+00, 2.324e+00,\n",
       "       2.425e+00, 2.526e+00, 2.627e+00, 2....\n",
       "       6.667e+00, 6.768e+00, 6.869e+00, 6.970e+00, 7.071e+00, 7.172e+00,\n",
       "       7.273e+00, 7.374e+00, 7.475e+00, 7.576e+00, 7.677e+00, 7.778e+00,\n",
       "       7.879e+00, 7.980e+00, 8.081e+00, 8.182e+00, 8.283e+00, 8.384e+00,\n",
       "       8.485e+00, 8.586e+00, 8.687e+00, 8.788e+00, 8.889e+00, 8.990e+00,\n",
       "       9.091e+00, 9.192e+00, 9.293e+00, 9.394e+00, 9.495e+00, 9.596e+00,\n",
       "       9.697e+00, 9.798e+00, 9.899e+00, 1.000e+01])},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=lasso, param_grid={'alpha':alphas}, cv=10, return_train_score=True)\n",
    "grid.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8150997219334934"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8150997219334934"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "best_model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8641956550086276\n",
      "{'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(grid.cv_results_.keys())\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014322</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.847024</td>\n",
       "      <td>0.874326</td>\n",
       "      <td>0.875806</td>\n",
       "      <td>0.873436</td>\n",
       "      <td>0.858280</td>\n",
       "      <td>0.872171</td>\n",
       "      <td>0.863711</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>0.849160</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.864196</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.869637</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.86975</td>\n",
       "      <td>0.865814</td>\n",
       "      <td>0.866713</td>\n",
       "      <td>0.864298</td>\n",
       "      <td>0.867341</td>\n",
       "      <td>0.865514</td>\n",
       "      <td>0.868829</td>\n",
       "      <td>0.868686</td>\n",
       "      <td>0.86739</td>\n",
       "      <td>0.001744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.102</td>\n",
       "      <td>{'alpha': 0.10200000000000001}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010270</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.203</td>\n",
       "      <td>{'alpha': 0.203}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.304</td>\n",
       "      <td>{'alpha': 0.30400000000000005}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.405</td>\n",
       "      <td>{'alpha': 0.405}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.011358</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>9.596</td>\n",
       "      <td>{'alpha': 9.596}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>9.697</td>\n",
       "      <td>{'alpha': 9.697000000000001}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>9.798</td>\n",
       "      <td>{'alpha': 9.798}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>9.899</td>\n",
       "      <td>{'alpha': 9.899000000000001}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.010885</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.014322      0.002962         0.003141        0.002527       0.001   \n",
       "1        0.010622      0.001607         0.003099        0.001985       0.102   \n",
       "2        0.010270      0.001280         0.003049        0.002339       0.203   \n",
       "3        0.010692      0.001124         0.003482        0.002379       0.304   \n",
       "4        0.010285      0.000926         0.003179        0.003307       0.405   \n",
       "..            ...           ...              ...             ...         ...   \n",
       "95       0.011358      0.002064         0.001818        0.001962       9.596   \n",
       "96       0.010368      0.001458         0.003799        0.002237       9.697   \n",
       "97       0.010778      0.001563         0.002733        0.001813       9.798   \n",
       "98       0.010501      0.002100         0.002627        0.003156       9.899   \n",
       "99       0.010885      0.002352         0.003612        0.003115          10   \n",
       "\n",
       "                            params  split0_test_score  split1_test_score  \\\n",
       "0                 {'alpha': 0.001}           0.847024           0.874326   \n",
       "1   {'alpha': 0.10200000000000001}          -0.002731          -0.000102   \n",
       "2                 {'alpha': 0.203}          -0.002731          -0.000102   \n",
       "3   {'alpha': 0.30400000000000005}          -0.002731          -0.000102   \n",
       "4                 {'alpha': 0.405}          -0.002731          -0.000102   \n",
       "..                             ...                ...                ...   \n",
       "95                {'alpha': 9.596}          -0.002731          -0.000102   \n",
       "96    {'alpha': 9.697000000000001}          -0.002731          -0.000102   \n",
       "97                {'alpha': 9.798}          -0.002731          -0.000102   \n",
       "98    {'alpha': 9.899000000000001}          -0.002731          -0.000102   \n",
       "99                 {'alpha': 10.0}          -0.002731          -0.000102   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0            0.875806           0.873436           0.858280   \n",
       "1           -0.000446          -0.000893          -0.007221   \n",
       "2           -0.000446          -0.000893          -0.007221   \n",
       "3           -0.000446          -0.000893          -0.007221   \n",
       "4           -0.000446          -0.000893          -0.007221   \n",
       "..                ...                ...                ...   \n",
       "95          -0.000446          -0.000893          -0.007221   \n",
       "96          -0.000446          -0.000893          -0.007221   \n",
       "97          -0.000446          -0.000893          -0.007221   \n",
       "98          -0.000446          -0.000893          -0.007221   \n",
       "99          -0.000446          -0.000893          -0.007221   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.872171           0.863711           0.893189   \n",
       "1           -0.003430          -0.002500          -0.001291   \n",
       "2           -0.003430          -0.002500          -0.001291   \n",
       "3           -0.003430          -0.002500          -0.001291   \n",
       "4           -0.003430          -0.002500          -0.001291   \n",
       "..                ...                ...                ...   \n",
       "95          -0.003430          -0.002500          -0.001291   \n",
       "96          -0.003430          -0.002500          -0.001291   \n",
       "97          -0.003430          -0.002500          -0.001291   \n",
       "98          -0.003430          -0.002500          -0.001291   \n",
       "99          -0.003430          -0.002500          -0.001291   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.849160           0.834854         0.864196        0.016261   \n",
       "1           -0.001199          -0.011676        -0.003149        0.003448   \n",
       "2           -0.001199          -0.011676        -0.003149        0.003448   \n",
       "3           -0.001199          -0.011676        -0.003149        0.003448   \n",
       "4           -0.001199          -0.011676        -0.003149        0.003448   \n",
       "..                ...                ...              ...             ...   \n",
       "95          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "96          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "97          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "98          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "99          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 1            0.869637            0.867315   \n",
       "1                 2            0.000000            0.000000   \n",
       "2                 2            0.000000            0.000000   \n",
       "3                 2            0.000000            0.000000   \n",
       "4                 2            0.000000            0.000000   \n",
       "..              ...                 ...                 ...   \n",
       "95                2            0.000000            0.000000   \n",
       "96                2            0.000000            0.000000   \n",
       "97                2            0.000000            0.000000   \n",
       "98                2            0.000000            0.000000   \n",
       "99                2            0.000000            0.000000   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0              0.86975            0.865814            0.866713   \n",
       "1              0.00000            0.000000            0.000000   \n",
       "2              0.00000            0.000000            0.000000   \n",
       "3              0.00000            0.000000            0.000000   \n",
       "4              0.00000            0.000000            0.000000   \n",
       "..                 ...                 ...                 ...   \n",
       "95             0.00000            0.000000            0.000000   \n",
       "96             0.00000            0.000000            0.000000   \n",
       "97             0.00000            0.000000            0.000000   \n",
       "98             0.00000            0.000000            0.000000   \n",
       "99             0.00000            0.000000            0.000000   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             0.864298            0.867341            0.865514   \n",
       "1             0.000000            0.000000            0.000000   \n",
       "2             0.000000            0.000000            0.000000   \n",
       "3             0.000000            0.000000            0.000000   \n",
       "4             0.000000            0.000000            0.000000   \n",
       "..                 ...                 ...                 ...   \n",
       "95            0.000000            0.000000            0.000000   \n",
       "96            0.000000            0.000000            0.000000   \n",
       "97            0.000000            0.000000            0.000000   \n",
       "98            0.000000            0.000000            0.000000   \n",
       "99            0.000000            0.000000            0.000000   \n",
       "\n",
       "    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.868829            0.868686           0.86739         0.001744  \n",
       "1             0.000000            0.000000           0.00000         0.000000  \n",
       "2             0.000000            0.000000           0.00000         0.000000  \n",
       "3             0.000000            0.000000           0.00000         0.000000  \n",
       "4             0.000000            0.000000           0.00000         0.000000  \n",
       "..                 ...                 ...               ...              ...  \n",
       "95            0.000000            0.000000           0.00000         0.000000  \n",
       "96            0.000000            0.000000           0.00000         0.000000  \n",
       "97            0.000000            0.000000           0.00000         0.000000  \n",
       "98            0.000000            0.000000           0.00000         0.000000  \n",
       "99            0.000000            0.000000           0.00000         0.000000  \n",
       "\n",
       "[100 rows x 31 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014322</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.847024</td>\n",
       "      <td>0.874326</td>\n",
       "      <td>0.875806</td>\n",
       "      <td>0.873436</td>\n",
       "      <td>0.858280</td>\n",
       "      <td>0.872171</td>\n",
       "      <td>0.863711</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>0.849160</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.864196</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.869637</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.86975</td>\n",
       "      <td>0.865814</td>\n",
       "      <td>0.866713</td>\n",
       "      <td>0.864298</td>\n",
       "      <td>0.867341</td>\n",
       "      <td>0.865514</td>\n",
       "      <td>0.868829</td>\n",
       "      <td>0.868686</td>\n",
       "      <td>0.86739</td>\n",
       "      <td>0.001744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.010271</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>6.364</td>\n",
       "      <td>{'alpha': 6.364000000000001}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.010096</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>7.374</td>\n",
       "      <td>{'alpha': 7.3740000000000006}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.010277</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>7.273</td>\n",
       "      <td>{'alpha': 7.273000000000001}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>7.172</td>\n",
       "      <td>{'alpha': 7.172000000000001}</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.014322      0.002962         0.003141        0.002527       0.001   \n",
       "63       0.010271      0.000605         0.003003        0.001850       6.364   \n",
       "73       0.010096      0.000498         0.002808        0.002881       7.374   \n",
       "72       0.010277      0.001718         0.003733        0.002921       7.273   \n",
       "71       0.010949      0.002089         0.003553        0.002456       7.172   \n",
       "\n",
       "                           params  split0_test_score  split1_test_score  \\\n",
       "0                {'alpha': 0.001}           0.847024           0.874326   \n",
       "63   {'alpha': 6.364000000000001}          -0.002731          -0.000102   \n",
       "73  {'alpha': 7.3740000000000006}          -0.002731          -0.000102   \n",
       "72   {'alpha': 7.273000000000001}          -0.002731          -0.000102   \n",
       "71   {'alpha': 7.172000000000001}          -0.002731          -0.000102   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0            0.875806           0.873436           0.858280   \n",
       "63          -0.000446          -0.000893          -0.007221   \n",
       "73          -0.000446          -0.000893          -0.007221   \n",
       "72          -0.000446          -0.000893          -0.007221   \n",
       "71          -0.000446          -0.000893          -0.007221   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.872171           0.863711           0.893189   \n",
       "63          -0.003430          -0.002500          -0.001291   \n",
       "73          -0.003430          -0.002500          -0.001291   \n",
       "72          -0.003430          -0.002500          -0.001291   \n",
       "71          -0.003430          -0.002500          -0.001291   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.849160           0.834854         0.864196        0.016261   \n",
       "63          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "73          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "72          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "71          -0.001199          -0.011676        -0.003149        0.003448   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 1            0.869637            0.867315   \n",
       "63                2            0.000000            0.000000   \n",
       "73                2            0.000000            0.000000   \n",
       "72                2            0.000000            0.000000   \n",
       "71                2            0.000000            0.000000   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0              0.86975            0.865814            0.866713   \n",
       "63             0.00000            0.000000            0.000000   \n",
       "73             0.00000            0.000000            0.000000   \n",
       "72             0.00000            0.000000            0.000000   \n",
       "71             0.00000            0.000000            0.000000   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             0.864298            0.867341            0.865514   \n",
       "63            0.000000            0.000000            0.000000   \n",
       "73            0.000000            0.000000            0.000000   \n",
       "72            0.000000            0.000000            0.000000   \n",
       "71            0.000000            0.000000            0.000000   \n",
       "\n",
       "    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.868829            0.868686           0.86739         0.001744  \n",
       "63            0.000000            0.000000           0.00000         0.000000  \n",
       "73            0.000000            0.000000           0.00000         0.000000  \n",
       "72            0.000000            0.000000           0.00000         0.000000  \n",
       "71            0.000000            0.000000           0.00000         0.000000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.sort_values('mean_test_score', ascending=False).head(5)\n",
    "# look for the best test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1af0c989790>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_results['mean_train_score'].plot(label='mean train score')\n",
    "cv_results['mean_test_score'].plot(label='mean test score')\n",
    "plt.legend(loc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso model (user provides alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 1000,\n",
       " 'normalize': True,\n",
       " 'positive': False,\n",
       " 'precompute': False,\n",
       " 'random_state': None,\n",
       " 'selection': 'cyclic',\n",
       " 'tol': 0.0001,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2 = Lasso(alpha=0.001, normalize=True)\n",
    "lasso2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, normalize=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.862928167056262\n",
      "Test score:  0.8150997219334934\n"
     ]
    }
   ],
   "source": [
    "print('Train score: ', lasso2.score(Xtrain,ytrain))\n",
    "print('Test score: ', lasso2.score(Xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8150997219334934"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the intercept is: 5.19\n"
     ]
    }
   ],
   "source": [
    "print('the intercept is: %.2f' %(lasso2.intercept_))\n",
    "coefs = pd.Series(lasso2.coef_, index=housefeature.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea_Log           0.328279\n",
       "OverallQual             0.089394\n",
       "LotArea_Log             0.041643\n",
       "GarageCars              0.037038\n",
       "KitchenQual             0.027080\n",
       "Fireplaces              0.008819\n",
       "YearBuilt               0.001020\n",
       "YearRemodAdd            0.000619\n",
       "BsmtQual                0.000571\n",
       "TotalBsmtSF             0.000093\n",
       "BsmtFinSF1              0.000057\n",
       "Exterior1st__ImStucc    0.000000\n",
       "Exterior1st__MetalSd   -0.000000\n",
       "Exterior1st__Plywood   -0.000000\n",
       "MasVnrType__BrkFace     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03107515020465086"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean((lasso2.predict(Xtest)-ytest)**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1762814516750156"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(mse)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "scores = ms.cross_val_score(estimator=lasso2, X=Xtrain, y=ytrain, cv=5)\n",
    "scores = pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.865\n",
      "1    0.879\n",
      "2    0.869\n",
      "3    0.882\n",
      "4    0.846\n",
      "dtype: float64\n",
      "----------------------------------------\n",
      "Score Mean 0.868\n",
      "Score std deviation: 0.014\n"
     ]
    }
   ],
   "source": [
    "print(scores.round(3))\n",
    "print('-'*40)\n",
    "print('Score Mean %.3f' %(scores.mean()))\n",
    "print('Score std deviation: %.3f' %(scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
